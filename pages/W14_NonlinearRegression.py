# W14_NonlinearRegression.py
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

st.set_page_config(layout="wide")
st.title("ç¬¬ 14 é€±ï½œéç·šæ€§è¿´æ­¸èˆ‡å¤šé …å¼å›æ­¸")
st.caption("ğŸ“˜ æ•™ç§‘æ›¸ç¬¬ 10 ç« ï½œéç·šæ€§æ“¬åˆèˆ‡å·¥ç¨‹é æ¸¬")

np.random.seed(42)
X = np.linspace(50, 200, 25).reshape(-1, 1)
Y = 0.01*X**2 - 0.5*X + 10 + np.random.normal(0, 2, 25)

degree = st.slider("å¤šé …å¼éšæ•¸", 1, 5, 2)

poly = PolynomialFeatures(degree=degree)
X_poly = poly.fit_transform(X)

model = LinearRegression()
model.fit(X_poly, Y)

Y_pred = model.predict(X_poly)

# ç¢ºä¿ä¸€ç¶­
Y = np.ravel(Y)
Y_pred = np.ravel(Y_pred)
X_flat = X.ravel()

residuals = Y - Y_pred

# é¡¯ç¤ºä¿‚æ•¸ - ä¿®æ­£ç‰ˆæœ¬
coefficients = np.concatenate([np.array([model.intercept_]), model.coef_[1:]])
st.write(f"è¿´æ­¸ä¿‚æ•¸ b0~b{degree}:", np.round(coefficients, 3))
st.write(f"RÂ² = {r2_score(Y, Y_pred):.3f}")

# æ•£ä½ˆåœ–èˆ‡æ“¬åˆæ›²ç·š
fig, ax = plt.subplots()
ax.scatter(X_flat, Y, color='blue', label='å¯¦æ¸¬å€¼')
ax.plot(X_flat, Y_pred, color='red', label=f'{degree}æ¬¡å¤šé …å¼æ“¬åˆ')
ax.set_xlabel("X")
ax.set_ylabel("Y")
ax.legend()
st.pyplot(fig)

# æ®˜å·®åœ–
fig2, ax2 = plt.subplots()
ax2.scatter(range(len(residuals)), residuals)
ax2.axhline(0, color='red', linestyle='--')
ax2.set_xlabel("æ¨£æœ¬ç·¨è™Ÿ")
ax2.set_ylabel("æ®˜å·®")
ax2.set_title("æ®˜å·®åœ–")
st.pyplot(fig2)
